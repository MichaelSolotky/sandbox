\documentclass[unicode]{article}

\usepackage[russian]{babel}
\usepackage[cp1251]{inputenc}
\usepackage{color}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphics}
\usepackage{epsfig}
\usepackage[colorlinks,urlcolor=blue]{hyperref}

\textheight=24cm
\textwidth=18cm
\oddsidemargin=-1cm
\topmargin=-2.5cm
\sloppy

\newcounter{example}

\def\vec#1{\mathchoice{\mbox{\boldmath$\displaystyle#1$}}
{\mbox{\boldmath$\textstyle#1$}} {\mbox{\boldmath$\scriptstyle#1$}} {\mbox{\boldmath$\scriptscriptstyle#1$}}}

\newcommand{\tr}{\mathop{\mathrm{tr}}\limits}

\DeclareMathOperator{\R}{U}
\DeclareMathOperator{\B}{Beta}
\DeclareMathOperator{\Par}{Pareto}

\renewcommand{\labelitemi}{$-$}

\pagestyle{empty}

\title{Теоретическое домашнее задание по матричным вычислениям}
\author{Солоткий Михаил, 417 группа ВМК МГУ}

\begin{document}
\maketitle

\begin{enumerate}
    \item Доказать тождество Вудбери:
        $$
            (A+UCV)^{-1} = A^{-1} - A^{-1}U(C^{-1} + VA^{-1}U)^{-1}VA^{-1}.
        $$
        Здесь $A\in\mathbb{R}^{n{\times}n}$, $C\in\mathbb{R}^{m{\times}m}$, $U\in\mathbb{R}^{n{\times}m}$, $V\in\mathbb{R}^{m{\times}n}$. \\ \\
        {\bf Решение:} \\
            Т.к. $A + U C V$ -- квадратная невырожденная матрица, из равенства $(A + U C V) B = I$ следует, что $B = (A + U C V)^{-1}$ \\
            $(A + UCV) (A^{-1} - A^{-1} U (C^{-1} + V A^{-1} U)^{-1} V A^{-1}) =$
            $I + U C V A^{-1} - U(I + C V A^{-1} U)(C^{-1} + V A^{-1} U)^{-1} V A^{-1} =$
            $= I + U C V A^{-1} - U C (C^{-1} + V A^{-1}U)(C^{-1} + V A^{-1} U)^{-1} V A^{-1}=$
            $= I + U C V A^{-1} - U C V A^{-1} = I$

    \item Пусть $p(\vec{x}) = \mathcal{N}(\vec{x}|\vec{\mu},\Sigma)$, $p(\vec{y}|\vec{x}) = \mathcal{N}(\vec{y}|A\vec{x},\Gamma)$, $A\in\mathbb{R}^{m{\times}n}$. Найти распределение $p(\vec{x}|\vec{y})$. \\ \\
        {\bf Решение:} \\
            $p(\vec{x} | \vec{y}) =$
            $\cfrac {p(\vec{y} | \vec{x}) p(\vec{x})}{\int p(\vec{y} | \vec{x}) p(\vec{x}) d \vec{x}}$ \\
            $p(\vec{y} | \vec{x}) p(\vec{x}) = \cfrac{1}{(2 \pi)^{\frac{m}{2}} \sqrt{\det(\Gamma)}} \exp \Big( \cfrac{1}{2} (\vec{y} - A \vec{x})^T \Gamma^{-1} (\vec{y} - A \vec{x})\Big)$
            $\cfrac{1}{(2 \pi)^{\frac{n}{2}} \sqrt{\det(\Sigma)}} \exp \Big( \cfrac{1}{2} (\vec{x} - \vec{\mu})^T \Sigma^{-1} (\vec{x} - \vec{\mu})\Big)$ \\ \\
            Распишем показатель экспоненты числителя: \\
            $$\cfrac{1}{2} \Big( \vec{y}^T \Gamma^{-1} \vec{y} + \vec{\mu}^T \Sigma^{-1} \vec{\mu} - 2 \vec{y}^T \Gamma^{-1} A \vec{x} - 2 \vec{\mu}^T \Sigma^{-1} \vec{x} + \vec{x}^T A^T \Gamma^{-1} A \vec{x} + \vec{x}^T \Sigma^{-1} \vec{x} \Big) =$$
            $$= \cfrac{1}{2} \Big( \vec{x}^T (A^T \Gamma^{-1} A + \Sigma^{-1}) \vec{x} - 2 (\vec{y}^T \Gamma^{-1} A + \vec{\mu}^T \Sigma^{-1}) \vec{x} + const(\vec{x}) \Big)$$ \\
            Отсюда можно выделить полный квадрат. В знаменателе стоит $p(\vec{y})$. Так как в правдоподобии мат. ожидание зависит от апроирного распределения, а ковариационная матрица не зависит, в результате умножения и интегрирования по $\vec{x}$ функциональный класс останется тот же (отрицательно определённая квадратичная форма под экспонентой). В результате деления числителя на знаменатель в формуле Байеса получится функция, которая по переменной $\vec{x}$ представляет из себя отрицательную квадратичную форму под экспонентой. Формально даже выделение полного квадрата можно до конца не проводить, главное -- понять, какие множители рядом с $\vec{x}$ и квадратичной частью $\vec{x}$. Так как матрицы - обобщение чисел, можно воспользоваться формулами для одномерного случая, зная, что в многомерном случае деление заменится на взятие обратной матрицы, а $\vec{x}^2$ -- на $\vec{x}^T \vec{x}$. \\
            $$\frac{1}{2} a x^2 - b x = \frac{1}{2} a \Big(x^2 - 2 \frac{b}{a} x \Big) = \frac{1}{2} a \Big(x - \frac{b}{a} \Big)^2 - \frac{1}{2} a \cfrac{b^2}{a^2}$$
            $$p(\vec{x} | \vec{y}) = \mathcal{N} \Big( \vec{x} | (A^T \Gamma^{-1} A + \Sigma^{-1})^{-1} (\vec{y}^T \Gamma^{-1} A + \vec{\mu}^T \Sigma^{-1}), (A^T \Gamma^{-1} A + \Sigma^{-1})^{-1} \Big)$$
    \item Вычислить $\mathbb{E}_{\mathcal{N}(\vec{x}|\vec{\mu},\Sigma)}(\vec{x}-\vec{a})^TB(\vec{x}-\vec{a})$; \\ \\
        {\bf Решение:} \\
            $\mathbb{E}_{\mathcal{N}(\vec{x}|\vec{\mu},\Sigma)}(\vec{x}-\vec{a})^TB(\vec{x}-\vec{a}) =$
            $\mathbb{E}_{\mathcal{N}(\vec{x}|\vec{\mu},\Sigma)} \Big[ \vec{x}^T B \vec{x} - 2 \vec{x}^T B a + a^T B a \Big]$ \\
            $\mathbb{E}_{\mathcal{N}(\vec{x}|\vec{\mu},\Sigma)} \vec{x}^T B \vec{x} = \mathbb{E}_{\mathcal{N}(\vec{x}|\vec{\mu},\Sigma)} \sum\limits_{i = 1}^n \sum\limits_{j = 1}^n x_i B_{ij} x_j = \Big \{ cov(x_i, x_j) = \mathbb{E} (x_i x_j) - \mathbb{E} x_i \mathbb{E}  x_j \Big \} =$
            $\sum\limits_{i = 1}^n \sum\limits_{j = 1}^n (\Sigma_{ij} + \mu_i \mu_j) B_{ij} =$ \\
            $= \tr \Big( (\Sigma + \vec{\mu} \vec{\mu}^T)^T B \Big) = \tr \Big( (\Sigma + \vec{\mu} \vec{\mu}^T) B \Big)$ \\
            $\mathbb{E}_{\mathcal{N}(\vec{x}|\vec{\mu},\Sigma)} 2 \vec{x}^T B a = 2 \vec{\mu}^T B a$ \\
            $\mathbb{E}_{\mathcal{N}(\vec{x}|\vec{\mu},\Sigma)}(\vec{x}-\vec{a})^TB(\vec{x}-\vec{a}) = \tr \Big( (\Sigma + \vec{\mu} \vec{\mu}^T) B \Big) + 2 \vec{\mu}^T B a$
    \item Вычислить $\frac{\partial}{\partial X}\det(X^{-1}+A)$ (все матрицы не являются симметричными); \\ \\
        {\bf Решение:} \\
            $X^{-1} + A = X^{-1} ( I + X A )$ \\
            $\det(X^{-1} + A) = \det(X^{-1}) \det(I + XA)$ \\
            $\frac{\partial}{\partial X_{ij}} \det(X) =$
            $\sum\limits_{k = 1}^n \frac{\partial x_{kj}}{\partial X_{ij}} \hat{A}_{jk} $, где $\hat{A}$ -- матрица алгебраических дополнений матрицы $X$. \\
            $X^{-1}_{ij} = \frac{1}{\det(X)} \hat{A}_{ji}$ \\
            $\frac{\partial}{\partial X_{ij}} \det(X) = det(X) X_{ji}^{-1}$ \\
            $\frac{\partial}{\partial X_{ij}} \det(I + XA) = \sum\limits_{k=1}^n \sum\limits_{l=1}^n \frac{\partial \det(I + XA)}{\partial (I +XA)_{kl}} \frac{\partial (I + XA)_{kl}}{\partial X_{ij}}$ \\
            $\frac{\partial \det(I + XA)}{\partial (I +XA)} = \det(I + XA) (I + XA)^{-T}$ \\
            $\frac{\partial (I + XA)_{kl}}{\partial X_{ij}} = 0$, если $i \neq k$ \\
            $(I + XA)_{il} = (I_{il} + \sum\limits_{p = 1}^n X_{ip} A_{pl})$ \\
            $\frac{\partial (I + XA)_{il}}{\partial X_{ij}} = A_{jl}$ \\
            $\frac{\partial}{\partial X_{ij}} \det(I + XA) = A (I + XA)^{-1}$ \\
            $\frac{\partial}{\partial X_{ij}} \Big[ \det(X) \det(I + XA) \Big] = $
            $\cfrac{1}{\det(X)^2} \det(X) \det(I + XA) X^{-T} + \det(X) \det(I + XA) A (I + XA)^{-1}$
    %\item Вычислить $\frac{\partial}{\partial X}\tr(AX^{-T}BXC)$ (все матрицы не являются симметричными, матрицы $A,C$ не являютcя квадратными). \\ \\
       % {\bf Решение:} \\
            %Пусть $X \in \mathbb{R}^{n \times n}$, тогда $A \in \mathbb{R}^{m \times n}$, $B \in \mathbb{R}^{n \times n}$. \\
            %Так как след определяется только для квадратных матриц $C \in \mathbb{R}^{n \times m}$ \\
            %$\frac{\partial}{\partial X_{ij}} \tr(A \underbrace{X^{-T} B X}_{Y \in \mathbb{R}^{n \times n}} C) = \sum\limits_{g=1}^n \sum\limits_{h=1}^n \cfrac{\partial \tr(A X^{-T} B X C)}{\partial (X^{-T} B X)_{gh}} \cfrac{\partial(X^{-T} B X)_{gh}}{\partial X_{ij}}$ \\
            %$\sum\limits_{k = 1}^m \cfrac{\partial}{\partial Y_{gh}} (AYC)_{kk} = \sum\limits_{k=1}^m \cfrac{\partial}{\partial Y_{ij}} \Big( \sum\limits_{p=1}^n A_{kp} (YC)_{pk} \Big) =$
            %$\sum\limits_{k=1}^m \sum\limits_{p=1}^n A_{kp} \cfrac{\partial}{\partial Y_{gh}} (YC)_{pk} =$
            %$\sum\limits_{k=1}^m \sum\limits_{p=1}^n \sum\limits_{s=1}^n \cfrac{\partial}{\partial Y_{gh}} \Big( A_{kp} Y_{ps} C_{sk} \Big) =$
            %$= \sum\limits_{p=1}^n \sum\limits_{s=1}^n \frac{\partial Y_{ps}}{\partial Y_{gh}} \sum\limits_{k=1}^m C_{sk} A_{kp} =$
            %$(CA)_{hg}$ \\
\end{enumerate}


\end{document}
